# Experimental protocol

### Material needed

- Two computers capable of running VR, each with their Vive Pro Eye, and one having a facial tracker, and needed SDK installed (Vive console, SRanipal, Srworks, SteamVR)
- Two Vive tracking stations.
- A table with two chairs on each side, front-to-front, with the map printed on top.
- 11 4X4 ArUco markers, n°0 to 9 were 13cm side and on wooden plank with a cube of polystyrene beneath for easy pick up, n°10 was 21.5cm side. 
- Preferably two other computers / tablet for the participants to fill the questionnaires.

### Pre-experiment 

Assign the participants in pair together. Make sur to assign which one will have the facial tracker and the other the lip sync, and which type of avatars they'll have.

### Settings

Before welcoming the participants, start the server and the apps on both pc, and activate the right avatar/gender/ethnicity/facial animation. Fill up the ip, participant id and secret word (We chosed Clock for the one with the facial tracker, and smartphone for the lipsync). Make sure "Skip eye callibration" is not checked. 

### Participants set-up

The experiment is done in pairs who do not know each other personally. They are brought in the experiment room, where they are given a consent form.
After the consent form, a brief speech is given to them concerning the content of the experiment. The content of the speech is :

  1. A demographic survey will be given to them.
  2. Once filled, they will sit at the table, and put on the headset.
  3. When they're ready, eye calibration will start. It will first ask them to move their headset up and down at the right place, then turn a knob to place a cursor at the right place (show them the knob). Finally, they will be ask to follow a point with their eyes. Once it's done, after a small loading they'll see the real world with the headset's cameras
  4. They will be asked to look at an ArUco marker 10 (n° is for your information only) on the wall for real/ virtual world correspondance.
  5. Once they're both ready, the first task will start in 15 seconds.
  6. The first task is a guessing game, they'll both have a secret word. One of them asks up to 20 yes/no questions, and when the first one is finished, the other one plays. Remind them to count on their fingers so they don't loose the count.
  7. Once finished, the second task will start. On the ArUco markers (1 to 9) will appear buildings with their name above. (Show them a picture of all buildings so they know them beforehand). Instructions will appear to place the buildings, such as "Building A is to the north", "Building B is next to building C". Their instructions are different, but complementary to find a possible configuration of the buildings. Attract their attention to the map, that there is 9 neighboorhoods, one for each building, that there is a river, two parks and a compass available.
  8. When they are finished, they will be able to press a red button that appears on the last marker (N°0). They can take the button in hand and press it. It goes green for the one who pressed it, and when its green for both, the application stops.
  9. They fill up two last questionnaire.

Any remaining questions are then answered. They are then directed to the computers, just after being given their participant ID. Demographic questionnaire can be seen here : https://forms.gle/XUwesiyL8aK91eFa7. It asks for participant's ID, age, gender, experience with video game (None, very limited, some previous , familiar) and VR (same). Once they're finished, if it is a group with avatars, show them a picture with the available avatars (cartoon or realistic) and ask them to pick one to represent them during the experiment. Specify that they can take the same one if they wish. When they have chosen, they sit at the table. Make sure of who has the facial tracker and who doesn't. For us, it was chosen beforehand and we asked the participants to sit at the right place at the table, so they have the right headset.

Help them put on the headset if needed, make sure the app is set up properly, then press the "Start experiment" button. Eye calibration will then start, answer their questions is needed and make sure the callibration doesn't fail. (Restart if callibration fails, sometimes glasses were an issue, but not always). When they see the real world, ask them to look at marker n°10 if they don't. After the 15 seconds countdown, the first task starts. MAKE SURE TO START THE AUDIO RECORD !

### First task

Instructions will appear. Usually, experimenter intervention is not needed, but if they are confused at the start and directly ask you questions, answer them.
They are allowed to say their word after the 20 questions if the other has not found it. Once they are finished, press the Go to next task button on both pcs.

### Second task

Once again, instructions will appear, answer questions if needed. They finish the task by themselves, tell them to pick up the button if they don't and have difficulty to press it.

### Post experiment

Bring them to the questionnaires on the computers, first the NASA TLX (with our app) and then the second questionnaire. Once they're finished, you can tell them they are free to leave or stay to ask questions and listen to the goal of the experiment.




    
